# ğŸ“ Voice-to-Notes API

A lightweight Node.js + Express server that turns spoken updates into **actionable notes**.  
It records audio, transcribes it with **OpenAI Whisper**, then analyzes the text with **GPT-4o-mini** to produce concise summaries, keywords, and improvement suggestions.

> **Live Repository:** [metu4669/voice_logger_app](https://github.com/metu4669/voice_logger_app)

---

## âœ¨ Features
- ğŸ¤ **Audio Uploads** â€“ Accepts `.webm` audio files through a single `POST /transcribe` endpoint.
- ğŸ—£ï¸ **Automatic Transcription** â€“ High-accuracy speech-to-text using OpenAIâ€™s `whisper-1`.
- ğŸ§  **Smart Note Analysis** â€“  
  1. Summarizes the update in one sentence.  
  2. Extracts keywords or tasks.  
  3. Suggests solutions or improvements based on the request.

---

## ğŸ› ï¸ Tech Stack
- **Node.js** + **Express**
- **Multer** for file uploads
- **OpenAI API** (`whisper-1` for transcription, `gpt-4o-mini` for analysis)

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/metu4669/voice_logger_app.git
cd voice_logger_app
```

### 2. Install Dependencies
```bash
npm install
```

### 3. Environment Variables

Create a .env file based on the included example:

```bash
cp .env.example .env
```


Edit .env:

OPENAI_API_KEY=your_openai_api_key_here
PORT=3000

### 4. Run the Server
```bash
npm start
```

The API will run at http://localhost:3000

ğŸ§© API Endpoint
POST /transcribe

Upload a single audio file (audio field).

Request Example

curl -X POST http://localhost:3000/transcribe \
  -F "audio=@sample.webm"


Response Example

{
  "transcription": "Userâ€™s spoken text here...",
  "analysis": "Summary, keywords, and suggestions."
}

ğŸ“‚ Project Structure
.
â”œâ”€ uploads/        # Temporary audio files (auto-cleaned)
â”œâ”€ server.js       # Main Express server
â”œâ”€ package.json
â”œâ”€ .env.example    # Environment variable template
â””â”€ .gitignore
